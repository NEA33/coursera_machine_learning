{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "data = pandas.read_csv('svm-data.csv', names = ['y', 'x1', 'x2'])\n",
    "y = data['y']\n",
    "X = data[['x1', 'x2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=241,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C=10000, kernel='linear', random_state=241)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('week3_1', 'w') as f:\n",
    "    for i in clf.support_:\n",
    "        if (i == clf.support_[-1]):\n",
    "            f.write(str(i+1))\n",
    "        else:\n",
    "            f.write(str(i+1)+' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "newgroups = datasets.fetch_20newsgroups(subset='all', categories=['alt.atheism', 'sci.space'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(newgroups.data)\n",
    "y = newgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=241, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='linear',\n",
       "                           max_iter=-1, probability=False, random_state=241,\n",
       "                           shrinking=True, tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([  1.00000000e-05,   1.00000000e-04,   1.00000000e-03,\n",
       "         1.00000000e-02,   1.00000000e-01,   1.00000000e+00,\n",
       "         1.00000000e+01,   1.00000000e+02,   1.00000000e+03,\n",
       "         1.00000000e+04,   1.00000000e+05])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "clf = svm.SVC(kernel='linear', random_state=241)\n",
    "gs = GridSearchCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 2.89339085,  3.14146705,  3.17180233,  2.96373768,  2.35462308,\n",
       "         1.44409008,  1.50693269,  1.48974361,  1.45045156,  1.41234512,\n",
       "         1.41954041]),\n",
       " 'std_fit_time': array([ 0.09429025,  0.24460848,  0.23859844,  0.17424846,  0.05293676,\n",
       "         0.04012865,  0.07126104,  0.03862553,  0.04076665,  0.02560154,\n",
       "         0.02382609]),\n",
       " 'mean_score_time': array([ 0.6902915 ,  0.75363197,  0.76601   ,  0.69207683,  0.57974205,\n",
       "         0.33614254,  0.35922904,  0.33664217,  0.33269186,  0.31971641,\n",
       "         0.32103615]),\n",
       " 'std_score_time': array([ 0.01783272,  0.05501029,  0.06062213,  0.02356935,  0.04172501,\n",
       "         0.01130776,  0.01674682,  0.01902233,  0.01649601,  0.00870549,\n",
       "         0.00897661]),\n",
       " 'param_C': masked_array(data = [1.0000000000000001e-05 0.0001 0.001 0.01 0.10000000000000001 1.0 10.0\n",
       "  100.0 1000.0 10000.0 100000.0],\n",
       "              mask = [False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 1.0000000000000001e-05},\n",
       "  {'C': 0.0001},\n",
       "  {'C': 0.001},\n",
       "  {'C': 0.01},\n",
       "  {'C': 0.10000000000000001},\n",
       "  {'C': 1.0},\n",
       "  {'C': 10.0},\n",
       "  {'C': 100.0},\n",
       "  {'C': 1000.0},\n",
       "  {'C': 10000.0},\n",
       "  {'C': 100000.0}],\n",
       " 'split0_test_score': array([ 0.54469274,  0.54469274,  0.54469274,  0.54469274,  0.95810056,\n",
       "         0.99441341,  0.99441341,  0.99441341,  0.99441341,  0.99441341,\n",
       "         0.99441341]),\n",
       " 'split1_test_score': array([ 0.57983193,  0.57983193,  0.57983193,  0.57983193,  0.94957983,\n",
       "         0.9859944 ,  0.9859944 ,  0.9859944 ,  0.9859944 ,  0.9859944 ,\n",
       "         0.9859944 ]),\n",
       " 'split2_test_score': array([ 0.57142857,  0.57142857,  0.57142857,  0.57142857,  0.95798319,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split3_test_score': array([ 0.50140056,  0.50140056,  0.50140056,  0.50140056,  0.93557423,\n",
       "         0.99159664,  0.99159664,  0.99159664,  0.99159664,  0.99159664,\n",
       "         0.99159664]),\n",
       " 'split4_test_score': array([ 0.56582633,  0.56582633,  0.56582633,  0.56582633,  0.94957983,\n",
       "         0.99439776,  0.99439776,  0.99439776,  0.99439776,  0.99439776,\n",
       "         0.99439776]),\n",
       " 'mean_test_score': array([ 0.55263158,  0.55263158,  0.55263158,  0.55263158,  0.95016797,\n",
       "         0.99328108,  0.99328108,  0.99328108,  0.99328108,  0.99328108,\n",
       "         0.99328108]),\n",
       " 'std_test_score': array([ 0.02811723,  0.02811723,  0.02811723,  0.02811723,  0.00821778,\n",
       "         0.00455086,  0.00455086,  0.00455086,  0.00455086,  0.00455086,\n",
       "         0.00455086]),\n",
       " 'rank_test_score': array([8, 8, 8, 8, 7, 1, 1, 1, 1, 1, 1], dtype=int32)}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=241,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C = gs.best_params_['C'], kernel='linear', random_state=241)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24019"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = abs(coef.toarray()[0])\n",
    "arr.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24019, 12871,  5088,  5093, 17802, 23673, 21850,  5776, 15606, 22936])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.argsort()[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['space', 'god', 'atheism', 'atheists', 'moon', 'sky', 'religion', 'bible', 'keith', 'sci']\n"
     ]
    }
   ],
   "source": [
    "feature_mapping = vectorizer.get_feature_names()\n",
    "top_words = []\n",
    "for i in arr.argsort()[::-1][:10]:\n",
    "    top_words.append(feature_mapping[i])\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('week3_2', 'w') as f:\n",
    "    for word in sorted(top_words):\n",
    "        if (word == sorted(top_words)[-1]):\n",
    "            f.write(word)\n",
    "        else:\n",
    "            f.write(word + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "data = pandas.read_csv('data-logistic.csv', names = ['y', 'x1', 'x2'])\n",
    "y = data['y']\n",
    "X = data[['x1', 'x2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_w(X, y, w, k, t):\n",
    "    n = len(w)\n",
    "    l = len(y)\n",
    "    w1 = np.zeros(n) \n",
    "    for i in range(n):\n",
    "        S = 0\n",
    "        for j in range(l):\n",
    "            S += y.iloc[j]*X.iloc[j,i]*(1-1./(1+np.exp(-y[j]*(w[0]*X.iloc[j,0]+w[1]*X.iloc[j,1]))))\n",
    "        w1[i] += w[i] + k/l*S - k*t*w[i]\n",
    "    return w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_Q(X, y, w, t):\n",
    "    l = len(y)\n",
    "    Q = 0\n",
    "    for i in range(l):\n",
    "        Q += np.log2(1+np.exp(-y[i]*(w[0]*X.iloc[i,0]+w[1]*X.iloc[i,1])))\n",
    "    Q = Q/l + t*sum([w[0]**2, w[1]**2])\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_euclid(w1, w2):\n",
    "    s = 0\n",
    "    for i in range(len(w1)):\n",
    "        s += (w1[i]-w2[i])**2\n",
    "    return np.sqrt(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, w, k, t, max_iter, eps):\n",
    "    i = 0\n",
    "    while (True):\n",
    "        Q = loss_Q(X,y,w,t)\n",
    "        w1 = new_w(X,y,w,k,t)\n",
    "        if (dist_euclid(w,w1) < eps):\n",
    "            break\n",
    "        w = w1\n",
    "        i += 1\n",
    "        if (i == iter):\n",
    "            print(\"Iter max\")\n",
    "            break\n",
    "    y_scores = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        y_scores[i] += 1./(1+np.exp(-w1[0]*X.iloc[i,0]-w1[1]*X.iloc[i,1]))\n",
    "    return y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# без регуляризации\n",
    "w = np.zeros(2)\n",
    "t = 0\n",
    "k = 0.1\n",
    "max_iter = 10000\n",
    "eps = 0.00001\n",
    "\n",
    "y_scores = logistic_regression(X,y,w,k,t,max_iter,eps)\n",
    "roc = roc_auc_score(y, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# с регуляризацией\n",
    "w_regular = np.zeros(2)\n",
    "t = 10\n",
    "k = 0.1\n",
    "max_iter = 10000\n",
    "eps = 0.00001\n",
    "\n",
    "y_scores_regular = logistic_regression(X,y,w_regular,k,t,max_iter,eps)\n",
    "roc_regular = roc_auc_score(y, y_scores_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.92685714285714282, 0.93628571428571417)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('week3_3', 'w') as f:\n",
    "    f.write(str(round(roc,3)) + ' ' + str(round(roc_regular,3)))\n",
    "roc, roc_regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 \n",
    "data = pandas.read_csv('classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = data['true']\n",
    "y_pred = data['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_false (y_true, y_pred):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_true[i] == 1):\n",
    "            if (y_pred[i] == 1):\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if (y_pred[i] == 0):\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    return (TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (TP, TN, FP, FN):\n",
    "    return ((TP+TN)/(TP+TN+FP+FN))\n",
    "\n",
    "def precision (TP, FP):\n",
    "    return (TP/(TP+FP))\n",
    "\n",
    "def recall (TP, FN):\n",
    "    return (TP/(TP+FN))\n",
    "\n",
    "def f_score (TP, FP, FN):\n",
    "    prec = precision(TP, FP)\n",
    "    rec = recall(TP, FN)\n",
    "    return (2*prec*rec/(prec+rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, TN, FP, FN = true_false(y_true, y_pred)\n",
    "acc = round(accuracy(TP, TN, FP, FN),2)\n",
    "prec = round(precision(TP, FP),2)\n",
    "rec = round(recall(TP, FN),2)\n",
    "f_ = round(f_score(TP, FP, FN),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 34, 59, 64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('week3_4', 'w') as f:\n",
    "    f.write(str(TP) + ' ' + str(FP) + ' ' + str(FN) + ' ' + str(TN))\n",
    "TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.54, 0.56, 0.42, 0.48)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('week3_5', 'w') as f:\n",
    "    f.write(str(acc) + ' ' + str(prec) + ' ' + str(rec) + ' ' + str(f_))\n",
    "acc, prec, rec, f_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = data['true']\n",
    "score_logreg = data['score_logreg']\n",
    "score_svm = data['score_svm']\n",
    "score_knn = data['score_knn']\n",
    "score_tree = data['score_tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72 0.71 0.64 0.69\n"
     ]
    }
   ],
   "source": [
    "roc_auc_score_logreg = roc_auc_score(y_true, score_logreg)\n",
    "roc_auc_score_svm = roc_auc_score(y_true, score_svm)\n",
    "roc_auc_score_knn = roc_auc_score(y_true, score_knn)\n",
    "roc_auc_score_tree = roc_auc_score(y_true, score_tree)\n",
    "print(round(roc_auc_score_logreg,2), round(roc_auc_score_svm,2), round(roc_auc_score_knn,2), round(roc_auc_score_tree,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('week3_6', 'w') as f:\n",
    "    f.write('score_logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_logreg, rec_logreg, thresholds_logreg = precision_recall_curve(y_true, score_logreg)\n",
    "prec_svm, rec_svm, thresholds_svm = precision_recall_curve(y_true, score_svm)\n",
    "prec_knn, rec_knn, thresholds_knn = precision_recall_curve(y_true, score_knn)\n",
    "prec_tree, rec_tree, thresholds_tree = precision_recall_curve(y_true, score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651785714286 score_tree\n"
     ]
    }
   ],
   "source": [
    "name = \"\"\n",
    "max_prec = 0\n",
    "m_rec = 0.7\n",
    "for i in range(len(prec_logreg)):\n",
    "    if (rec_logreg[i] >= m_rec and prec_logreg[i] > max_prec):\n",
    "        max_prec = prec_logreg[i]\n",
    "        name = 'score_logreg'\n",
    "for i in range(len(rec_svm)):\n",
    "    if (rec_svm[i] >= m_rec and prec_svm[i] > max_prec):\n",
    "        max_prec = prec_svm[i]\n",
    "        name = 'score_svm'\n",
    "for i in range(len(rec_knn)):\n",
    "    if (rec_knn[i] >= m_rec and prec_knn[i] > max_prec):\n",
    "        max_prec = prec_knn[i]\n",
    "        name = 'score_knn'\n",
    "for i in range(len(rec_tree)):\n",
    "    if (rec_tree[i] >= m_rec and prec_tree[i] > max_prec):\n",
    "        max_prec = prec_tree[i]\n",
    "        name = 'score_tree'\n",
    "print(max_prec, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('week3_7', 'w') as f:\n",
    "    f.write(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
